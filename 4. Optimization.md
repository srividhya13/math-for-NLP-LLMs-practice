## Optimization  
### *(Core for training neural nets and LLMs)*

**Topics :**

- Convex Sets and Convex Functions  
- Gradient Descent  
- Stochastic Gradient Descent (SGD)  
- Momentum, RMSProp, Adam Optimizer  
- Lagrange Multipliers  
- Constrained Optimization Techniques  
- Cost and Loss Functions  
- Convergence Criteria and Learning Rate Scheduling  
- Saddle Points, Local Minima, and Global Minima  
